# Code Review 实践指南

> 基于真实项目评审经验总结的方法论，适用于前端/全栈项目。

---

## 一、评审心态

做 code review 最常见的误区是把它当成"挑错大会"。几个原则：

**1. 先理解再评判**

不要看到不熟悉的写法就标记为问题。先搞清楚作者为什么这样写。很多看起来"不对"的代码背后有框架限制、历史原因或刻意的权衡。

典型反面案例：在 `output: "export"` 的 Next.js 项目里建议加 middleware — 这是评审者不了解技术约束导致的误判。

**2. 区分"必须修"和"可以改"**

每条评审意见都应该有明确的优先级。如果所有问题都标成"重要"，等于没有优先级。实际操作中，一个项目真正需要立刻修的问题通常不超过 5 个。

**3. 承认自己会错**

评审报告应该留有勘误的空间。提出的建议被作者合理反驳时，应该坦然接受并更新结论，而不是坚持原判。

**4. 尊重项目阶段**

对一个快速迭代期的 MVP 要求 100% 测试覆盖率是不合理的。评审建议的合理性取决于项目当前所处的阶段和团队的实际情况。

---

## 二、评审维度

以下是我做评审时会逐一过的维度，按从高到低的权重排列。

### 第一层：正确性（必查）

这是最高优先级。代码是否按预期工作？

| 检查项 | 常见问题 |
|--------|----------|
| 逻辑错误 | 条件判断恒真/恒假（如 `x \|\| true`）、off-by-one、边界条件 |
| 状态管理 | 竞态条件、状态不同步、缺少清理（useEffect 没有 cleanup） |
| 数据流 | props 传递断裂、context 值过期、异步操作 cancelled flag |
| 类型安全 | `as any` 掩盖了真实类型错误、非空断言 `!` 在重构后失效 |

**检查方法**：重点看分支逻辑、异步操作、状态更新。尝试在脑中推演边界场景（空数组、null 值、并发请求）。

### 第二层：健壮性

代码在异常情况下是否优雅降级？

| 检查项 | 常见问题 |
|--------|----------|
| 错误处理 | catch 块静默吞异常、缺少 try-catch 的危险操作 |
| 输入校验 | 用户输入/外部数据未验证就使用 |
| 降级策略 | 配置加载失败时无提示、第三方服务不可用时无兜底 |
| 空值处理 | 可选链滥用掩盖了 null 传播链、`undefined` 被渲染到页面 |

**判断标准**：不是所有地方都需要错误处理。内部函数间的调用可以信任参数，但**系统边界**（用户输入、文件 I/O、网络请求、JSON 解析、第三方库调用）必须有防护。

```
信任区 ←——————————→ 防护区
内部纯函数调用           用户输入
模块间参数传递           文件系统操作
常量和配置引用           JSON.parse
                        外部 API 调用
                        动态 import
```

### 第三层：安全性

| 检查项 | 说明 |
|--------|------|
| 路径遍历 | 用户可控的文件路径是否包含 `..` 检查 |
| XSS | `dangerouslySetInnerHTML` 的内容来源是否可信 |
| 注入 | SQL 拼接、命令拼接、模板注入 |
| 敏感信息 | API key、密码是否硬编码在代码中 |
| 依赖安全 | 已知漏洞的第三方包 |

**注意**：不要对所有场景都套用安全检查。静态构建时的文件读取和生产环境的用户输入，风险等级完全不同。评审时要结合执行上下文判断实际风险。

### 第四层：可维护性

代码是否容易被未来的开发者（包括你自己）理解和修改？

| 检查项 | 判断标准 |
|--------|----------|
| 命名 | 变量/函数名能否不看上下文就大致理解用途 |
| 函数长度 | 超过 50 行的函数需要关注，超过 100 行大概率需要拆分 |
| 嵌套深度 | if/for 嵌套超过 3 层就需要提取函数或提前 return |
| 重复代码 | 相同逻辑出现 3 次以上值得提取；2 次可以容忍 |
| 魔法值 | 需要区分：语义不明的值（应命名）vs 上下文清晰的值（可保留） |
| 注释 | 好代码很少需要注释；需要注释的通常是"为什么"而不是"做了什么" |

**关于重复代码的经验法则**：

> 两次重复不急着抽象，三次重复再提取。
>
> — Rule of Three

过早抽象比重复更危险。当你只有两个调用者时，你不知道第三个调用者会以什么形式出现。强行抽象出的公共函数可能在第三个场景下需要大量参数或条件分支，反而比重复代码更难维护。

### 第五层：性能

| 检查项 | 常见问题 |
|--------|----------|
| 不必要的计算 | 组件每次渲染都重新创建对象/函数、循环内重复 I/O |
| React 重渲染 | 缺少 `useCallback`/`useMemo` 导致子组件无意义重渲染 |
| 内存泄漏 | 事件监听器/定时器/Observer 未清理 |
| 包体积 | 整包导入（`import lodash`）而非按需导入（`import get from 'lodash/get'`） |
| 网络 | 缺少防抖/节流、没有取消过期请求 |

**注意**：不要把性能优化当成默认要求。`useMemo` 和 `useCallback` 本身有成本，只在确实存在性能问题时才建议添加。过度的 memo 化反而让代码更难读。

### 第六层：工程规范

| 检查项 | 说明 |
|--------|------|
| 一致性 | 同一个项目中相同的事情是否用相同的方式处理 |
| 样式管理 | 是否遵循项目约定的方式（如统一使用 `cn()` 而非模板字符串） |
| 文件组织 | 新增的文件是否放在了合理的目录下 |
| 导入顺序 | 是否遵循项目的 import 规范 |
| TypeScript | 是否充分利用了类型系统，而非用 `any` 逃逸 |

这一层的评审标准完全取决于项目本身的约定。没有对错，只有一致或不一致。

### 第七层：可访问性（Web 项目）

| 检查项 | 说明 |
|--------|------|
| 语义化 HTML | 是否使用了正确的标签（`<button>` vs `<div onClick>`） |
| ARIA 属性 | 交互元素是否有 `aria-label`、`aria-expanded` 等 |
| 键盘操作 | 所有交互是否可以不用鼠标完成 |
| 焦点管理 | 弹窗打开时焦点是否正确转移和捕获 |
| 颜色对比 | 文字与背景的对比度是否满足 WCAG AA |

---

## 三、评审流程

### Step 1：建立全局认知（10 分钟）

在逐行看代码之前，先了解全局：

```
1. 读 README / 项目文档 → 了解这个项目是什么、做什么
2. 看目录结构           → 模块划分、分层方式
3. 看 package.json     → 技术栈、依赖版本
4. 看配置文件           → 构建方式、环境约束
5. 看 git log          → 最近在做什么、代码活跃度
```

这一步的目的是建立**评审上下文**。后续所有评审意见都应该在这个上下文下提出。脱离上下文的评审意见往往是错误的。

### Step 2：识别核心路径

找到项目中最关键的代码路径，优先评审：

```
核心业务逻辑 > 数据处理层 > 公共组件 > 页面组件 > 工具函数 > 配置文件
```

不要平均分配注意力。一个项目中 20% 的代码承载了 80% 的风险。

### Step 3：逐文件/模块评审

对每个文件，按以下顺序检查：

```
1. 正确性    → 这段代码能正确工作吗？
2. 健壮性    → 异常情况下会怎样？
3. 安全性    → 有没有安全隐患？
4. 可维护性  → 6 个月后还能看懂吗？
5. 性能      → 有没有明显的性能问题？
```

### Step 4：交叉检查

单个文件没问题不代表整体没问题。需要跨文件检查：

- **重复逻辑**：多个文件中是否有类似的代码？
- **一致性**：同样的事情在不同地方是否用了不同的做法？
- **依赖关系**：模块间的依赖是否合理？是否有循环依赖？
- **数据流**：从配置到页面的数据传递链是否完整？

### Step 5：输出评审报告

---

## 四、评审报告写法

### 结构模板

```markdown
# 项目代码评审报告

## 总评（一段话 + 评分表）
## 架构评审（目录结构、配置体系、关键决策）
## 分模块评审（按文件/目录逐个分析）
## 跨文件问题（重复代码、一致性、数据流）
## 优化建议（按优先级排列）
## 亮点（好的设计值得记录）
## 结论
```

### 每条评审意见的格式

好的评审意见包含四要素：

```
1. 位置 — 哪个文件、哪一行
2. 问题 — 具体是什么问题（不是"代码不好"）
3. 影响 — 会导致什么后果
4. 建议 — 推荐的修复方式（最好有代码示例）
```

**好的评审意见**：

> `docs.ts:136` — `JSON.parse(raw)` 缺少 try-catch。如果用户的 `docs.json` 存在语法错误，这里会抛出未捕获的 SyntaxError，导致整站构建失败且错误信息不明确。建议包裹 try-catch 并输出文件路径和具体错误信息。

**差的评审意见**：

> docs.ts 的错误处理不够好，建议改进。

### 优先级定义

| 级别 | 含义 | 举例 |
|------|------|------|
| 🔴 高 | 影响正确性或稳定性，必须在合并前修复 | 逻辑错误、崩溃风险、安全漏洞 |
| 🟠 中 | 影响质量或可维护性，应该在本迭代内修复 | 缺少错误处理、代码重复、类型安全问题 |
| 🟡 低 | 改善代码风格，可以后续处理 | 命名优化、注释完善、微小重构 |

---

## 五、常见误判模式

做了足够多的 review 后，你会发现自己容易在这些地方犯错：

### 1. 脱离约束提建议

```
误判：建议使用 middleware 做路由拦截
事实：项目使用 output: "export"，不支持 middleware
教训：提建议前先确认技术栈的约束条件
```

### 2. 对理论风险过度担忧

```
误判：递归函数没有深度限制，可能栈溢出
事实：输入数据有天然上限（如 MDX 嵌套不超过 10 层）
教训：结合实际输入数据评估风险，不要只看理论可能性
```

### 3. 过度工程化建议

```
误判：建议引入 Zod 做配置校验
事实：TypeScript 编译期检查 + console.warn 已足够
教训：解决方案的复杂度应该匹配问题的复杂度
```

### 4. 忽视重复的成本

```
误判：两处相似代码应该立刻抽象为公共函数
事实：只有两个调用者，过早抽象可能在第三个场景下反而碍事
教训：Rule of Three — 等第三个调用者出现再抽象
```

### 5. 对防御性写法的误判

```
误判：aria-hidden + display:none 冗余，应该删掉一个
事实：两者语义不同，同时使用是常见的防御性做法
教训：冗余不等于错误，有些冗余是有意为之的安全网
```

### 6. 把风格偏好当成质量问题

```
误判：应该把 56.25%（16:9 比例）提取为常量
事实：这个值在 CSS 上下文中语义已经足够清晰
教训：区分"我会怎么写"和"这样写有问题"
```

---

## 六、Review 不同类型代码的侧重点

### 业务逻辑

- 重点看正确性和边界条件
- 确认是否覆盖了所有业务分支
- 检查错误处理是否给用户有意义的反馈

### UI 组件

- Props 接口设计是否合理（必选 vs 可选、默认值）
- 是否有不必要的重渲染
- 可访问性是否达标
- 样式管理是否和项目一致

### 工具函数 / lib

- 类型定义是否精确
- 是否有副作用（纯函数 vs 有状态）
- 边界输入的处理（空字符串、null、特殊字符）
- 是否有合理的 JSDoc

### 配置和构建

- 配置值是否和实际环境匹配
- 环境变量是否有兜底值
- 构建产物是否符合预期
- CI 脚本是否健壮（中间步骤失败的处理）

### API / 数据层

- 输入验证是否完整
- 返回值类型是否和文档一致
- 错误码和错误消息是否有意义
- 是否考虑了并发和幂等性

---

## 七、自查清单

做完评审后，用这个清单验证自己的评审质量：

- [ ] 是否在评审前充分了解了项目上下文和技术约束？
- [ ] 每条意见是否都有具体的文件位置和代码引用？
- [ ] 优先级划分是否合理？高优先级是否真的影响正确性/稳定性？
- [ ] 建议的修复方式是否在项目的技术约束内可行？
- [ ] 是否区分了"必须修"和"可以改"？
- [ ] 是否有把个人风格偏好当成质量问题？
- [ ] 对于不确定的问题，是否标注了"需要确认"而非直接定性？
- [ ] 是否记录了代码中好的设计，而不仅仅是问题？
- [ ] 建议的复杂度是否匹配问题的复杂度？
